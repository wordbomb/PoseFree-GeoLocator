{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcfd3e9-a7da-4546-b94c-ea43c24550a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994ff34-e040-42e0-8ef1-4b498f29868c",
   "metadata": {},
   "source": [
    "# Frame-by-frame extraction of the original video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8f017-d354-47bf-9e39-1b60c0969e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "origin_videos_path = \"origin_videos\"\n",
    "output_root_path = \"predict_datasets\"\n",
    "\n",
    "os.makedirs(output_root_path, exist_ok=True)\n",
    "\n",
    "for video_file in os.listdir(origin_videos_path):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(origin_videos_path, video_file)\n",
    "        video_stem = os.path.splitext(video_file)[0]\n",
    "        output_dir = os.path.join(output_root_path, video_stem)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if len(os.listdir(output_dir)) >= total_frames:\n",
    "            cap.release()\n",
    "            continue\n",
    "\n",
    "        frame_idx = 1\n",
    "\n",
    "        for _ in tqdm(range(total_frames), desc=video_stem):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_filename = f\"{video_stem}_{frame_idx:06d}.jpg\"\n",
    "            frame_path = os.path.join(output_dir, frame_filename)\n",
    "\n",
    "            if not os.path.exists(frame_path):\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "\n",
    "            frame_idx += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"{video_file} completed! \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5bebe2-ca2a-4405-9b8b-39eb7438248f",
   "metadata": {},
   "source": [
    "# Perform prediction on the extracted images frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b74fd-4f5e-48e5-8c91-910b65b5c08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the list of camera device names to use\n",
    "predict_datasets_root = \"predict_datasets\"\n",
    "camera_devices = [d for d in os.listdir(predict_datasets_root) if os.path.isdir(os.path.join(predict_datasets_root, d))]\n",
    "\n",
    "# Load the trained YOLOv12 model\n",
    "model_path = \"runs_UAV/yolov12n_bs48_img960/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Iterate over each camera device for prediction\n",
    "for camera_device in camera_devices:\n",
    "    # Define paths for the image folder and output folder\n",
    "    image_folder = os.path.join(predict_datasets_root, camera_device)\n",
    "    output_folder = os.path.join(r\"predict_results\", camera_device)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    image_files = [\n",
    "        f for f in os.listdir(image_folder)\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))\n",
    "    ]\n",
    "\n",
    "    print(f\"ðŸ“· {camera_device} is being processed\")\n",
    "    \n",
    "    for image_name in tqdm(image_files, desc=f\"{camera_device}\"):\n",
    "        # Get the full image path\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        \n",
    "        # Skip non-image files\n",
    "        if not image_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            continue\n",
    "        \n",
    "        # Perform object detection\n",
    "        results = model.predict(image_path, conf=0.25, iou=0.7, max_det=1, device=\"cuda:0\", verbose=False)\n",
    "        \n",
    "        # If a result is detected and there are boxes, process and save it\n",
    "        if results and len(results[0].boxes) > 0:\n",
    "            result = results[0]\n",
    "            img = result.orig_img\n",
    "            img_height, img_width = img.shape[:2]\n",
    "            obj = result.boxes[0]\n",
    "            class_id = int(obj.cls.item())\n",
    "            confidence = float(obj.conf.item())\n",
    "            bbox = obj.xyxy[0]\n",
    "            \n",
    "            # Calculate YOLO format label\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            x_center = (x_min + x_max) / 2 / img_width\n",
    "            y_center = (y_min + y_max) / 2 / img_height\n",
    "            width = (x_max - x_min) / img_width\n",
    "            height = (y_max - y_min) / img_height\n",
    "            label = f\"{int(class_id)} {x_center} {y_center} {width} {height} {float(confidence)}\\n\"\n",
    "            \n",
    "            # Save the detection to a TXT file\n",
    "            output_file = os.path.join(output_folder, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(label)\n",
    "\n",
    "print(\"All predictions have been processed and saved to TXT files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolov12)",
   "language": "python",
   "name": "yolov12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
